{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/M-NOVA288/Portfolio-/blob/main/Cat_Dog_Classification/MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PWYXK9sKicU",
        "outputId": "b7724ad0-2cbb-4030-ae99-f45d1e8c633a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# PART 1: Fully Connected Network - MNIST\n",
        "# ==========================================\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, regularizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# Normalize pixel values (0-1)\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_test = x_test.astype(\"float32\") / 255.0\n",
        "\n",
        "# Flatten images (28x28 -> 784)\n",
        "x_train = x_train.reshape(-1, 784)\n",
        "x_test = x_test.reshape(-1, 784)\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "y_train = keras.utils.to_categorical(y_train, 10)\n",
        "y_test = keras.utils.to_categorical(y_test, 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3730ccf"
      },
      "source": [
        "# Final Task\n",
        "\n",
        "### Subtask:\n",
        "Summarize the results of the MNIST classification task, including the model's design, training methodology, and its performance in terms of training and testing accuracies."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e271ccaa"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Q&A\n",
        "The MNIST classification task involved designing a fully connected network, training it, and evaluating its performance.\n",
        "\n",
        "*   **Model Design:** The network featured two hidden `Dense` layers, each with 50 nodes and `relu` activation. To mitigate overfitting, `L2 regularization` (factor 0.001), `BatchNormalization`, and `Dropout` (rate 0.3) were applied to these hidden layers. The output layer consisted of 10 `Dense` nodes with a `softmax` activation for classification.\n",
        "*   **Training Methodology:** The model was compiled with the `adam` optimizer, using `categorical_crossentropy` as the loss function and `accuracy` as the metric. Training ran for a maximum of 50 epochs with a batch size of 128. `EarlyStopping` (patience of 5 epochs on `val_loss`) and `ModelCheckpoint` (saving the best model based on `val_loss`) callbacks were utilized.\n",
        "*   **Performance:** The model achieved a training accuracy of 0.9739 and a testing accuracy of 0.9645.\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   The model architecture comprised two hidden `Dense` layers, each with 50 nodes and `relu` activation, followed by a 10-node `Dense` output layer with `softmax` activation.\n",
        "*   Regularization techniques, including L2 regularization (factor 0.001), Batch Normalization, and Dropout (rate 0.3), were applied to the hidden layers.\n",
        "*   The model was trained using the `adam` optimizer, `categorical_crossentropy` loss, and `accuracy` metric, with a batch size of 128 for up to 50 epochs.\n",
        "*   Training stability was managed with `EarlyStopping` (patience 5 on validation loss) and `ModelCheckpoint` to save the best performing model.\n",
        "*   The final evaluation showed a training accuracy of 0.9739 and a testing accuracy of 0.9645.\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   The model demonstrates strong performance on the MNIST dataset, with testing accuracy very close to training accuracy, indicating good generalization given the applied regularization techniques.\n",
        "*   To potentially further improve performance or robustness, one could explore a deeper architecture with more layers or different activation functions, or experiment with more advanced data augmentation techniques."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464
        },
        "id": "Pmyjii4kKvzs",
        "outputId": "ccd014a9-be6a-437d-bef7-a91f88a6d09b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">39,250</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,550</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">510</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │        \u001b[38;5;34m39,250\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │           \u001b[38;5;34m200\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │         \u001b[38;5;34m2,550\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │           \u001b[38;5;34m200\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m510\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">42,710</span> (166.84 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m42,710\u001b[0m (166.84 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">42,510</span> (166.05 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m42,510\u001b[0m (166.05 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">200</span> (800.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m200\u001b[0m (800.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Define model\n",
        "model = keras.Sequential()\n",
        "\n",
        "# Hidden Layer 1 (50 nodes, ReLU + L2 Regularization + Dropout)\n",
        "model.add(layers.Dense(50, activation='relu',\n",
        "                       kernel_regularizer=regularizers.l2(0.001),\n",
        "                       input_shape=(784,)))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Dropout(0.3))\n",
        "\n",
        "# Hidden Layer 2 (50 nodes, ReLU + L2 Regularization + Dropout)\n",
        "model.add(layers.Dense(50, activation='relu',\n",
        "                       kernel_regularizer=regularizers.l2(0.001)))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Dropout(0.3))\n",
        "\n",
        "# Output Layer\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75b9217b"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "best_lr_original = 0.001\n",
        "\n",
        "print(f\"Training model for original data with best learning rate: {best_lr_original}\")\n",
        "model_original_plot = create_cnn_model()\n",
        "model_original_plot.compile(optimizer=Adam(learning_rate=best_lr_original),\n",
        "                       loss='binary_crossentropy',\n",
        "                       metrics=['accuracy'])\n",
        "\n",
        "history_original_plot = model_original_plot.fit(x_train_original, y_train_original,\n",
        "                                                epochs=20,\n",
        "                                                batch_size=32,\n",
        "                                                validation_data=(x_test_original, y_test_original),\n",
        "                                                verbose=1)\n",
        "\n",
        "print(\"Optimization history for original data captured.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3b988d7d"
      },
      "source": [
        "best_lr_augmented = 0.001\n",
        "\n",
        "print(f\"Training model for augmented data with best learning rate: {best_lr_augmented}\")\n",
        "model_augmented_plot = create_cnn_model()\n",
        "model_augmented_plot.compile(optimizer=Adam(learning_rate=best_lr_augmented),\n",
        "                        loss='binary_crossentropy',\n",
        "                        metrics=['accuracy'])\n",
        "\n",
        "history_augmented_plot = model_augmented_plot.fit(datagen.flow(x_train_original, y_train_original, batch_size=32),\n",
        "                                                  epochs=20,\n",
        "                                                  validation_data=(x_test_original, y_test_original),\n",
        "                                                  verbose=1)\n",
        "\n",
        "print(\"Optimization history for augmented data captured.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75d36314"
      },
      "source": [
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history_original_plot.history['accuracy'])\n",
        "plt.plot(history_original_plot.history['val_accuracy'])\n",
        "plt.title('Model Accuracy (Original Data)')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history_original_plot.history['loss'])\n",
        "plt.plot(history_original_plot.history['val_loss'])\n",
        "plt.title('Model Loss (Original Data)')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "print(\"Optimization history plot for original data generated.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58714980"
      },
      "source": [
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history_augmented_plot.history['accuracy'])\n",
        "plt.plot(history_augmented_plot.history['val_accuracy'])\n",
        "plt.title('Model Accuracy (Augmented Data)')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history_augmented_plot.history['loss'])\n",
        "plt.plot(history_augmented_plot.history['val_loss'])\n",
        "plt.title('Model Loss (Augmented Data)')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "print(\"Optimization history plot for augmented data generated.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dCYBUU8CKxUp"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-xYqhfrVK0Am"
      },
      "outputs": [],
      "source": [
        "early_stop = EarlyStopping(monitor='val_loss',\n",
        "                           patience=5,\n",
        "                           restore_best_weights=True)\n",
        "\n",
        "checkpoint = ModelCheckpoint(\"best_mnist_model.h5\",\n",
        "                             monitor='val_loss',\n",
        "                             save_best_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IpfQ9KtSK2gQ",
        "outputId": "328367a9-e5ab-412c-cc8e-e914131c1d2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m366/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6599 - loss: 1.2045"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.6633 - loss: 1.1937 - val_accuracy: 0.9285 - val_loss: 0.3461\n",
            "Epoch 2/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8927 - loss: 0.4599"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8927 - loss: 0.4599 - val_accuracy: 0.9433 - val_loss: 0.2812\n",
            "Epoch 3/50\n",
            "\u001b[1m366/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9111 - loss: 0.3853"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9112 - loss: 0.3851 - val_accuracy: 0.9488 - val_loss: 0.2557\n",
            "Epoch 4/50\n",
            "\u001b[1m368/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9229 - loss: 0.3402"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9229 - loss: 0.3402 - val_accuracy: 0.9507 - val_loss: 0.2377\n",
            "Epoch 5/50\n",
            "\u001b[1m374/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9272 - loss: 0.3137"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9272 - loss: 0.3137 - val_accuracy: 0.9544 - val_loss: 0.2190\n",
            "Epoch 6/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9330 - loss: 0.2891"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9330 - loss: 0.2891 - val_accuracy: 0.9588 - val_loss: 0.1993\n",
            "Epoch 7/50\n",
            "\u001b[1m365/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9367 - loss: 0.2767"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9367 - loss: 0.2767 - val_accuracy: 0.9616 - val_loss: 0.1919\n",
            "Epoch 8/50\n",
            "\u001b[1m368/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9391 - loss: 0.2626"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9392 - loss: 0.2626 - val_accuracy: 0.9613 - val_loss: 0.1850\n",
            "Epoch 9/50\n",
            "\u001b[1m372/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9434 - loss: 0.2510"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9433 - loss: 0.2510 - val_accuracy: 0.9636 - val_loss: 0.1793\n",
            "Epoch 10/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9426 - loss: 0.2460 - val_accuracy: 0.9638 - val_loss: 0.1802\n",
            "Epoch 11/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9433 - loss: 0.2433"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9433 - loss: 0.2433 - val_accuracy: 0.9646 - val_loss: 0.1748\n",
            "Epoch 12/50\n",
            "\u001b[1m366/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9427 - loss: 0.2361"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9428 - loss: 0.2362 - val_accuracy: 0.9673 - val_loss: 0.1643\n",
            "Epoch 13/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9452 - loss: 0.2305 - val_accuracy: 0.9647 - val_loss: 0.1709\n",
            "Epoch 14/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9473 - loss: 0.2315 - val_accuracy: 0.9668 - val_loss: 0.1652\n",
            "Epoch 15/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9464 - loss: 0.2283 - val_accuracy: 0.9668 - val_loss: 0.1668\n",
            "Epoch 16/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9472 - loss: 0.2266 - val_accuracy: 0.9649 - val_loss: 0.1685\n",
            "Epoch 17/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9460 - loss: 0.2263 - val_accuracy: 0.9677 - val_loss: 0.1657\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(x_train, y_train,\n",
        "                    validation_split=0.2,\n",
        "                    epochs=50,\n",
        "                    batch_size=128,\n",
        "                    callbacks=[early_stop, checkpoint])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTTVcQXbLFQA",
        "outputId": "fd776bf0-b7cf-495f-e842-a9b1d80bdfef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9756 - loss: 0.1346\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9576 - loss: 0.1864\n",
            "Train Accuracy: 0.9738666415214539\n",
            "Test Accuracy: 0.9645000100135803\n"
          ]
        }
      ],
      "source": [
        "train_loss, train_acc = model.evaluate(x_train, y_train)\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "\n",
        "print(\"Train Accuracy:\", train_acc)\n",
        "print(\"Test Accuracy:\", test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEehqXMWLRiC",
        "outputId": "f6e76e52-11cf-4716-ee82-48f4f8a7b27e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading training data...\n",
            "Loaded 10000 training images.\n",
            "Loading testing data...\n",
            "Loaded 2000 testing images.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator # Import ImageDataGenerator\n",
        "\n",
        "# Function to load images and labels\n",
        "def load_data(image_folder, label_file):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    # Read all labels from the label file and collect (filename, label) pairs\n",
        "    data_points = []\n",
        "    with open(label_file, 'r') as f:\n",
        "        for line in f.readlines():\n",
        "            line = line.strip()\n",
        "            if line:\n",
        "                parts = line.split('\\t') # Split by tab\n",
        "                if len(parts) == 2:\n",
        "                    filename, label_str = parts\n",
        "                    data_points.append((filename, int(label_str)))\n",
        "                else:\n",
        "                    print(f\"Warning: Unexpected line format in {label_file}: {line}\")\n",
        "\n",
        "    # Process only the images explicitly listed in the label file\n",
        "    for filename, label in data_points:\n",
        "        img_path = os.path.join(image_folder, filename)\n",
        "        img = cv2.imread(img_path)\n",
        "\n",
        "        if img is None:\n",
        "            print(f\"Warning: Could not read image {img_path} (listed in {label_file}). Skipping.\")\n",
        "            continue\n",
        "\n",
        "        # Resize and normalize image\n",
        "        img = cv2.resize(img, (32, 32))\n",
        "        img = img / 255.0\n",
        "        images.append(img)\n",
        "        labels.append(label)\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Load training and testing data\n",
        "print(\"Loading training data...\")\n",
        "x_train, y_train = load_data(\"/content/cat_dog/train/\", \"/content/cat_dog/train_class_labels.txt\")\n",
        "print(f\"Loaded {len(x_train)} training images.\")\n",
        "print(\"Loading testing data...\")\n",
        "x_test, y_test = load_data(\"/content/cat_dog/test/\", \"/content/cat_dog/test_class_labels.txt\")\n",
        "print(f\"Loaded {len(x_test)} testing images.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6f5f53dc",
        "outputId": "011c1922-2859-4b16-fe99-d585bd8e45d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'cat_dog.zip' extracted successfully to '/content/'.\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Replace 'your_zip_file.zip' with the actual name of your uploaded zip file\n",
        "zip_file_name = 'cat_dog.zip'\n",
        "\n",
        "# Ensure the zip file exists before trying to extract\n",
        "if os.path.exists(zip_file_name):\n",
        "    with zipfile.ZipFile(zip_file_name, 'r') as zip_ref:\n",
        "        zip_ref.extractall('/content/') # Extract to the /content/ directory\n",
        "    print(f\"'{zip_file_name}' extracted successfully to '/content/'.\")\n",
        "else:\n",
        "    print(f\"Error: Zip file '{zip_file_name}' not found. Please check the file name and path.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36ad3471"
      },
      "source": [
        "## Import ImageDataGenerator\n",
        "\n",
        "### Subtask:\n",
        "Modify the `WEehqXMWLRiC` cell to import the `ImageDataGenerator` from `tensorflow.keras.preprocessing.image`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "784facdd"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask is to modify the `WEehqXMWLRiC` cell to import `ImageDataGenerator`. I will provide the updated code for that cell, including the new import statement.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5419fe1"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the `ImageDataGenerator` is imported, the next logical step is to initialize it with the specified augmentation parameters. This prepares the data generator for applying transformations to the training images.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2a4c11dd",
        "outputId": "8fe2762a-e841-4c1d-a95f-f8f7ae3d8a71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ImageDataGenerator initialized with augmentation parameters.\n"
          ]
        }
      ],
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "print(\"ImageDataGenerator initialized with augmentation parameters.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45cf08b6"
      },
      "source": [
        "**Reasoning**:\n",
        "With the `ImageDataGenerator` initialized, the next step is to define the Convolutional Neural Network (CNN) model. This model will later be trained using the augmented data for the cat/dog classification task.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        },
        "id": "d427c1c3",
        "outputId": "6162d754-6aea-458a-b5cd-917abba8e01f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m73,856\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_5 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m65,664\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">159,041</span> (621.25 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m159,041\u001b[0m (621.25 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">159,041</span> (621.25 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m159,041\u001b[0m (621.25 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model_cnn = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid') # Binary classification\n",
        "])\n",
        "\n",
        "model_cnn.summary()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0ac4a98"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming results_original and results_augmented are available from previous runs\n",
        "# If not, they would need to be re-executed, but the user requested to avoid execution.\n",
        "# For this response, I am relying on the presence of these variables in the kernel state.\n",
        "\n",
        "# Create a dictionary to store combined results\n",
        "combined_results = {}\n",
        "\n",
        "for lr in learning_rates:\n",
        "    combined_results[lr] = {\n",
        "        'Original Data Accuracy': results_original.get(lr, 'N/A'),\n",
        "        'Augmented Data Accuracy': results_augmented.get(lr, 'N/A')\n",
        "    }\n",
        "\n",
        "accuracy_df = pd.DataFrame.from_dict(combined_results, orient='index')\n",
        "accuracy_df.index.name = 'Learning Rate'\n",
        "display(accuracy_df)\n",
        "\n",
        "print(f\"\\nBest learning rate for original data: {best_lr_original}\")\n",
        "# If best_lr_augmented was also determined, it would be displayed here.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "589fc258"
      },
      "source": [
        "## Import ImageDataGenerator\n",
        "\n",
        "### Subtask:\n",
        "Modify the `WEehqXMWLRiC` cell to import the `ImageDataGenerator` from `tensorflow.keras.preprocessing.image`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "037863ed"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask is to modify the `WEehqXMWLRiC` cell to import `ImageDataGenerator`. I will provide the updated code for that cell, including the new import statement.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22fb66e2"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous steps corrected the data loading paths, ensuring `x_train`, `y_train`, `x_test`, and `y_test` are now correctly populated. The CNN model has been defined, and the `ImageDataGenerator` has been initialized. The next logical step is to compile and train the CNN model using the augmented data for training and the prepared test data for validation as per the subtask instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91233e00"
      },
      "source": [
        "## Import ImageDataGenerator\n",
        "\n",
        "### Subtask:\n",
        "Modify the `WEehqXMWLRiC` cell to import the `ImageDataGenerator` from `tensorflow.keras.preprocessing.image`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "039db11d"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires modifying cell `WEehqXMWLRiC` to import `ImageDataGenerator`. I will provide the full content of the cell with the added import statement.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9b26e5e4"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Q&A\n",
        "The MNIST classification task involved designing a fully connected network, training it, and evaluating its performance.\n",
        "\n",
        "*   **Model Design:** The network featured two hidden `Dense` layers, each with 50 nodes and `relu` activation. To mitigate overfitting, `L2 regularization` (factor 0.001), `BatchNormalization`, and `Dropout` (rate 0.3) were applied to these hidden layers. The output layer consisted of 10 `Dense` nodes with a `softmax` activation for classification.\n",
        "*   **Training Methodology:** The model was compiled with the `adam` optimizer, using `categorical_crossentropy` as the loss function and `accuracy` as the metric. Training ran for a maximum of 50 epochs with a batch size of 128. `EarlyStopping` (patience of 5 epochs on `val_loss`) and `ModelCheckpoint` (saving the best model based on `val_loss`) callbacks were utilized.\n",
        "*   **Performance:** The model achieved a training accuracy of 0.9739 and a testing accuracy of 0.9645.\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   The model architecture comprised two hidden `Dense` layers, each with 50 nodes and `relu` activation, followed by a 10-node `Dense` output layer with `softmax` activation.\n",
        "*   Regularization techniques, including L2 regularization (factor 0.001), Batch Normalization, and Dropout (rate 0.3), were applied to the hidden layers.\n",
        "*   The model was trained using the `adam` optimizer, `categorical_crossentropy` loss, and `accuracy` metric, with a batch size of 128 for up to 50 epochs.\n",
        "*   Training stability was managed with `EarlyStopping` (patience 5 on validation loss) and `ModelCheckpoint` to save the best performing model.\n",
        "*   The final evaluation showed a training accuracy of 0.9739 and a testing accuracy of 0.9645.\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   The model demonstrates strong performance on the MNIST dataset, with testing accuracy very close to training accuracy, indicating good generalization given the applied regularization techniques.\n",
        "*   To potentially further improve performance or robustness, one could explore a deeper architecture with more layers or different activation functions, or experiment with more advanced data augmentation techniques.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "754007f5"
      },
      "source": [
        "# Task\n",
        "Review that the MNIST dataset loading, normalization, flattening, and one-hot encoding are correctly performed in cell `4PWYXK9sKicU`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f14eac10"
      },
      "source": [
        "## Review MNIST Data Preparation\n",
        "\n",
        "### Subtask:\n",
        "Confirm that the MNIST dataset is loaded, normalized, flattened, and one-hot encoded as required, referring to the content of cell `4PWYXK9sKicU`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfb8174a"
      },
      "source": [
        "## Review MNIST Data Preparation\n",
        "\n",
        "### Findings from cell `4PWYXK9sKicU`:\n",
        "\n",
        "1.  **Dataset Loading:** The MNIST dataset is correctly loaded using `keras.datasets.mnist.load_data()`.\n",
        "2.  **Normalization:** Pixel values for both training (`x_train`) and testing (`x_test`) data are normalized to a 0-1 range by dividing by 255.0.\n",
        "3.  **Flattening:** Images are flattened from their 28x28 original shape to a 784-dimensional vector using `reshape(-1, 784)` for both `x_train` and `x_test`.\n",
        "4.  **One-Hot Encoding:** Labels (`y_train` and `y_test`) are converted to one-hot encoding using `keras.utils.to_categorical()` with 10 classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35c6cbcb"
      },
      "source": [
        "## Review Model Design\n",
        "\n",
        "### Subtask:\n",
        "Verify the model design in cell `Pmyjii4kKvzs` to ensure it includes two hidden dense layers with 50 nodes each, ReLU activation, an output layer with 10 nodes and softmax activation, and regularization techniques (L2 regularization, Batch Normalization, Dropout) applied to the hidden layers.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01abbb35"
      },
      "source": [
        "## Model Design Verification (Cell `Pmyjii4kKvzs`)\n",
        "\n",
        "The model design in cell `Pmyjii4kKvzs` has been verified against the specified criteria:\n",
        "\n",
        "1.  **First Hidden Dense Layer:** Confirmed. It has 50 nodes, `relu` activation, and `l2` regularization with a factor of 0.001.\n",
        "2.  **BatchNormalization (after first dense):** Confirmed. A `BatchNormalization` layer is applied immediately after the first `Dense` layer.\n",
        "3.  **Dropout (after first BatchNormalization):** Confirmed. A `Dropout` layer with a rate of 0.3 is applied after the first `BatchNormalization` layer.\n",
        "4.  **Second Hidden Dense Layer:** Confirmed. It has 50 nodes, `relu` activation, and `l2` regularization with a factor of 0.001.\n",
        "5.  **BatchNormalization (after second dense):** Confirmed. A `BatchNormalization` layer is applied immediately after the second `Dense` layer.\n",
        "6.  **Dropout (after second BatchNormalization):** Confirmed. A `Dropout` layer with a rate of 0.3 is applied after the second `BatchNormalization` layer.\n",
        "7.  **Output Dense Layer:** Confirmed. It has 10 nodes and `softmax` activation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5d45726d"
      },
      "source": [
        "## Review Model Compilation\n",
        "\n",
        "### Subtask:\n",
        "Check cell `dCYBUU8CKxUp` to confirm the model is compiled with the `adam` optimizer, `categorical_crossentropy` loss, and `accuracy` metrics.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ff69b57b"
      },
      "source": [
        "**Reasoning**:\n",
        "To verify the model compilation parameters, I need to display the content of the specified cell `dCYBUU8CKxUp`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cafbd9d"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "922a8bad"
      },
      "source": [
        "## Model Compilation Verification (Cell `dCYBUU8CKxUp`)\n",
        "\n",
        "The compilation parameters in cell `dCYBUU8CKxUp` have been verified against the specified criteria:\n",
        "\n",
        "1.  **Optimizer:** Confirmed. `optimizer='adam'` is specified.\n",
        "2.  **Loss Function:** Confirmed. `loss='categorical_crossentropy'` is specified.\n",
        "3.  **Metrics:** Confirmed. `metrics=['accuracy']` is included."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbe5cdbf"
      },
      "source": [
        "## Review Training Callbacks\n",
        "\n",
        "### Subtask:\n",
        "Examine cell `-xYqhfrVK0Am` to ensure `EarlyStopping` and `ModelCheckpoint` callbacks are correctly implemented with the specified parameters.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28ef8039"
      },
      "source": [
        "## Training Callbacks Verification (Cell `-xYqhfrVK0Am`)\n",
        "\n",
        "The training callbacks in cell `-xYqhfrVK0Am` have been verified against the specified criteria:\n",
        "\n",
        "1.  **EarlyStopping Implementation:** Confirmed.\n",
        "    *   `monitor='val_loss'`\n",
        "    *   `patience=5`\n",
        "    *   `restore_best_weights=True` (This is also implemented which is good practice).\n",
        "\n",
        "2.  **ModelCheckpoint Implementation:** Confirmed.\n",
        "    *   `filepath=\"best_mnist_model.h5\"` (The file path is correctly set to \"best_mnist_model.h5\")\n",
        "    *   `monitor='val_loss'`\n",
        "    *   `save_best_only=True`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7d48391"
      },
      "source": [
        "## Review Model Training Execution\n",
        "\n",
        "### Subtask:\n",
        "Confirm the model training in cell `IpfQ9KtSK2gQ` uses the correct batch size (128), maximum epochs (50), and incorporates the defined callbacks.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9b5fb5bd"
      },
      "source": [
        "**Reasoning**:\n",
        "To verify the model training parameters and callbacks, I will display the content of cell `IpfQ9KtSK2gQ`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e53e7e45"
      },
      "source": [
        "history = model.fit(x_train,\n",
        "                    y_train,\n",
        "                    validation_split=0.2,\n",
        "                    epochs=50,\n",
        "                    batch_size=128,\n",
        "                    callbacks=[early_stop, checkpoint])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81746659"
      },
      "source": [
        "# Task\n",
        "The output from cell `rTTVcQXbLFQA` confirms the model's training accuracy as 0.9738666415214539 and testing accuracy as 0.9645000100135803. These values align with the performance details reported in the summary cell `b3730ccf`.\n",
        "\n",
        "All specified requirements for the MNIST task have been successfully verified and documented within the notebook. The data preparation, model design including regularization, compilation parameters, training methodology with callbacks, and the final performance metrics are all accurately reflected."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0323cfe9"
      },
      "source": [
        "## Verify Accuracy Report\n",
        "\n",
        "### Subtask:\n",
        "Confirm that cell `rTTVcQXbLFQA` correctly prints the training and testing accuracies as observed from the output in the notebook, to ensure this step has been completed as requested.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7d640a3"
      },
      "source": [
        "## Accuracy Report Verification (Cell `rTTVcQXbLFQA`)\n",
        "\n",
        "Upon reviewing the `standard_output` of cell `rTTVcQXbLFQA`:\n",
        "\n",
        "1.  **Training Accuracy:** Confirmed. The output shows `Train Accuracy: 0.9738666415214539`, which is approximately 0.9739.\n",
        "2.  **Testing Accuracy:** Confirmed. The output shows `Test Accuracy: 0.9645000100135803`, which is approximately 0.9645.\n",
        "\n",
        "Both the training and testing accuracies are correctly printed and match the expected values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dc7c7ec6"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Summarize the completion of the MNIST task, confirming that all design, training, and reporting requirements have been satisfied by the existing notebook cells, drawing upon the details confirmed in the preceding review steps.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8942635"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   The training accuracy was confirmed to be approximately 0.9739 (\\$0.9738666415214539\\$).\n",
        "*   The testing accuracy was confirmed to be approximately 0.9645 (\\$0.9645000100135803\\$).\n",
        "*   Both the training and testing accuracies printed in the cell output match the expected values, confirming the correctness of the model's reported performance.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   All specified requirements for the MNIST task, including data preparation, model design with regularization, compilation parameters, training methodology with callbacks, and final performance metrics, have been successfully verified and accurately reflected in the notebook.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP2CUFCCxuzJ02LmuzbdAaZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}